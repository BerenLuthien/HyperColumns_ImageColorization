{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import TensorflowUtils as utils\n",
    "#import read_LaMemDataset as lamem\n",
    "import read_FlowersDataset as flowers\n",
    "import datetime\n",
    "import BatchDatsetReader as dataset\n",
    "from six.moves import xrange\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "from scipy.misc import imread\n",
    "from skimage import color\n",
    "from scipy.misc import toimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.flags.FLAGS\n",
    "tf.flags.DEFINE_integer(\"batch_size\", \"1\", \"batch size for training\")\n",
    "tf.flags.DEFINE_string(\"logs_dir\", \"logs\", \"path to logs directory\")\n",
    "tf.flags.DEFINE_string(\"data_dir\", \"Data_zoo/LaMem/\", \"path to dataset\")\n",
    "tf.flags.DEFINE_float(\"learning_rate\", \"1e-4\", \"Learning rate for Adam Optimizer\")\n",
    "tf.flags.DEFINE_float(\"beta1\", \"0.9\", \"Beta 1 value to use in Adam Optimizer\")\n",
    "tf.flags.DEFINE_string(\"model_dir\", \"Model_zoo/\", \"Path to vgg model mat\")\n",
    "tf.flags.DEFINE_bool('debug', \"False\", \"Debug mode: True/ False\")\n",
    "tf.flags.DEFINE_string('mode', \"train\", \"Mode train/ test\")\n",
    "MODEL_URL = 'http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat'\n",
    "IMAGE_SIZE = 128\n",
    "MAX_ITERATION = 12\n",
    "restore_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vgg_net(weights, image): # load the pre-trained VGG19 , https://arxiv.org/pdf/1409.1556.pdf\n",
    "    layers = (\n",
    "        # 'conv1_1', 'relu1_1',\n",
    "        # skip conv1_1 of VGG\n",
    "        'conv1_2', 'relu1_2', 'pool1',\n",
    "\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    "\n",
    "    net = {}\n",
    "    current = image\n",
    "    for i, name in enumerate(layers):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i + 2][0][0][0][0]\n",
    "            # matconvnet: weights are [width, height, in_channels, out_channels]\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = utils.get_variable(np.transpose(kernels, (1, 0, 2, 3)), name=name + \"_w\")\n",
    "            bias = utils.get_variable(bias.reshape(-1), name=name + \"_b\")\n",
    "            current = utils.conv2d_basic(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current, name=name)\n",
    "            if FLAGS.debug:\n",
    "                utils.add_activation_summary(current)\n",
    "        elif kind == 'pool':\n",
    "            current = utils.avg_pool_2x2(current)\n",
    "        net[name] = current\n",
    "    return net\n",
    "\n",
    "\n",
    "def HyperColumns(images, train_phase):\n",
    "    print(\"setting up vgg initialized conv layers ...\")\n",
    "    model_data = utils.get_model_data(FLAGS.model_dir, MODEL_URL)\n",
    "\n",
    "    weights = np.squeeze(model_data['layers'])\n",
    "\n",
    "    with tf.variable_scope(\"HyperColumns\") as scope:\n",
    "        # VGG takes in 3channel (RGB) images. \n",
    "        # In order to input 1-channel (gray) image, \n",
    "        # define a new filter that takes in gray color image and map it into 64 channels so as to fit VGG conv1_2\n",
    "        W0 = utils.weight_variable([3, 3, 1, 64], name=\"W0\")\n",
    "        b0 = utils.bias_variable([64], name=\"b0\")\n",
    "        conv0 = utils.conv2d_basic(images, W0, b0)\n",
    "        hrelu0 = tf.nn.relu(conv0, name=\"relu\")\n",
    "        image_net = vgg_net(weights, hrelu0)\n",
    "\n",
    "        # HyperColumns\n",
    "        # https://arxiv.org/abs/1411.5752\n",
    "        relu1_2  = image_net[\"relu1_2\"]\n",
    "        layer_relu1_2 = tf.image.resize_bilinear(relu1_2, (IMAGE_SIZE, IMAGE_SIZE)) \n",
    "\n",
    "        relu2_1  = image_net[\"relu2_1\"]\n",
    "        layer_relu2_1 = tf.image.resize_bilinear(relu2_1, (IMAGE_SIZE, IMAGE_SIZE)) \n",
    "        \n",
    "        relu2_2  = image_net[\"relu2_2\"]\n",
    "        layer_relu2_2 = tf.image.resize_bilinear(relu2_2, (IMAGE_SIZE, IMAGE_SIZE)) \n",
    "\n",
    "        relu3_1  = image_net[\"relu3_1\"]\n",
    "        layer_relu3_1 = tf.image.resize_bilinear(relu3_1, (IMAGE_SIZE, IMAGE_SIZE))         \n",
    "        relu3_2  = image_net[\"relu3_2\"]\n",
    "        layer_relu3_2 = tf.image.resize_bilinear(relu3_2, (IMAGE_SIZE, IMAGE_SIZE)) \n",
    "        relu3_3  = image_net[\"relu3_3\"]\n",
    "        layer_relu3_3 = tf.image.resize_bilinear(relu3_3, (IMAGE_SIZE, IMAGE_SIZE)) \n",
    "        \n",
    "        relu3_4  = image_net[\"relu3_4\"]\n",
    "        layer_relu3_4 = tf.image.resize_bilinear(relu3_4, (IMAGE_SIZE, IMAGE_SIZE))         \n",
    "        relu4_1  = image_net[\"relu4_1\"]\n",
    "        layer_relu4_1 = tf.image.resize_bilinear(relu4_1, (IMAGE_SIZE, IMAGE_SIZE)) \n",
    "        relu4_2  = image_net[\"relu4_2\"]\n",
    "        layer_relu4_2 = tf.image.resize_bilinear(relu4_2, (IMAGE_SIZE, IMAGE_SIZE)) \n",
    "        relu4_3  = image_net[\"relu4_3\"]\n",
    "        layer_relu4_3 = tf.image.resize_bilinear(relu4_3, (IMAGE_SIZE, IMAGE_SIZE)) \n",
    "        relu4_4  = image_net[\"relu4_4\"]\n",
    "        layer_relu4_4 = tf.image.resize_bilinear(relu4_4, (IMAGE_SIZE, IMAGE_SIZE)) \n",
    "        \n",
    "        relu5_1  = image_net[\"relu5_1\"]\n",
    "        layer_relu5_1 = tf.image.resize_bilinear(relu5_1, (IMAGE_SIZE, IMAGE_SIZE))         \n",
    "        relu5_2  = image_net[\"relu5_2\"]\n",
    "        layer_relu5_2 = tf.image.resize_bilinear(relu5_2, (IMAGE_SIZE, IMAGE_SIZE))         \n",
    "        relu5_3  = image_net[\"relu5_3\"]\n",
    "        layer_relu5_3 = tf.image.resize_bilinear(relu5_3, (IMAGE_SIZE, IMAGE_SIZE))         \n",
    "        relu5_4  = image_net[\"relu5_4\"]\n",
    "        layer_relu5_4 = tf.image.resize_bilinear(relu5_4, (IMAGE_SIZE, IMAGE_SIZE))        \n",
    "        \n",
    "        HyperColumns = tf.concat([layer_relu1_2, \\\n",
    "                                     layer_relu2_1, layer_relu2_2, \\\n",
    "                                     layer_relu3_1, layer_relu3_2, layer_relu3_3, layer_relu3_4, \\\n",
    "                                     layer_relu4_1, layer_relu4_2, layer_relu4_3, layer_relu4_4, \\\n",
    "                                     layer_relu5_1, layer_relu5_2, layer_relu5_3, layer_relu5_4  \\\n",
    "                                    ] ,3)\n",
    "        wc1 = utils.weight_variable([1, 1, 5440, 2], name=\"wc1\")\n",
    "        wc1_biase = utils.bias_variable([2], name=\"wc1_biase\")\n",
    "        pred_AB_conv = tf.nn.conv2d(HyperColumns, wc1, [1, 1, 1, 1], padding='SAME')\n",
    "        pred_AB = tf.nn.bias_add(pred_AB_conv, wc1_biase)        \n",
    "    return tf.concat(values=[images, pred_AB], axis=3,  name=\"pred_image\")\n",
    "\n",
    "def train(loss, var_list):\n",
    "    optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate, beta1=FLAGS.beta1)\n",
    "    grads = optimizer.compute_gradients(loss, var_list=var_list)\n",
    "    for grad, var in grads:\n",
    "        utils.add_gradient_summary(grad, var)\n",
    "    return optimizer.apply_gradients(grads)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Setting up network...\")\n",
    "train_phase = tf.placeholder(tf.bool, name=\"train_phase\")\n",
    "images = tf.placeholder(tf.float32, shape=[None, None, None, 1], name='L_images')\n",
    "lab_images = tf.placeholder(tf.float32, shape=[None, None, None, 3], name=\"LAB_images\")\n",
    "pred_image = HyperColumns(images, train_phase)\n",
    "\n",
    "gen_loss_mse = tf.reduce_mean(2 * tf.nn.l2_loss(pred_image - lab_images)) / (IMAGE_SIZE * IMAGE_SIZE * 100 * 100)\n",
    "tf.summary.scalar(\"HyperColumns_loss_MSE\", gen_loss_mse)\n",
    "\n",
    "train_variables = tf.trainable_variables()\n",
    "for v in train_variables:\n",
    "    utils.add_to_regularization_and_summary(var=v)\n",
    "\n",
    "train_op = train(gen_loss_mse, train_variables)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Reading image dataset...\")\n",
    "train_images, testing_images, validation_images = flowers.read_dataset(FLAGS.data_dir)\n",
    "image_options = {\"resize\": True, \"resize_size\": IMAGE_SIZE, \"color\": \"LAB\"}\n",
    "batch_reader_train = dataset.BatchDatset(train_images, image_options)\n",
    "batch_reader_validate = dataset.BatchDatset(validation_images, image_options)\n",
    "batch_reader_testing = dataset.BatchDatset(testing_images, image_options)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Setting up session\")\n",
    "sess = tf.Session()\n",
    "summary_op = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "train_writer = tf.summary.FileWriter(FLAGS.logs_dir + '/train', sess.graph)\n",
    "validate_writer = tf.summary.FileWriter(FLAGS.logs_dir + '/validate')\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if restore_model == True:\n",
    "    ckpt = tf.train.get_checkpoint_state(FLAGS.logs_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\"Model restored...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_variables_trainable = False\n",
    "if check_variables_trainable == True :\n",
    "    print('printing out the trainable variables...')\n",
    "    variables_names = [v.name for v in tf.trainable_variables()]\n",
    "    values = sess.run(variables_names)\n",
    "    for k, v in zip(variables_names, values):\n",
    "        print (\"Variable: \", k)\n",
    "        print (\"Shape: \", v.shape)\n",
    "\n",
    "mse_train_list = []\n",
    "if FLAGS.mode == 'train':\n",
    "        for itr in xrange(MAX_ITERATION):\n",
    "            l_image, color_images = batch_reader_train.next_batch(FLAGS.batch_size)\n",
    "            feed_dict = {images: l_image, lab_images: color_images, train_phase: True}\n",
    "\n",
    "            if itr % 10 == 0:\n",
    "                mse, summary_str = sess.run([gen_loss_mse, summary_op], feed_dict=feed_dict)\n",
    "                mse_train_list.append(mse)\n",
    "                train_writer.add_summary(summary_str, itr)\n",
    "                print(\"Step: %d, MSE: %g\" % (itr, mse))\n",
    "\n",
    "            if itr % 100 == 0:\n",
    "                saver.save(sess, FLAGS.logs_dir + \"model.ckpt\", itr)\n",
    "                pred = sess.run(pred_image, feed_dict=feed_dict)\n",
    "                idx = np.random.randint(0, FLAGS.batch_size)\n",
    "                save_dir = os.path.join(FLAGS.logs_dir, \"image_checkpoints\")\n",
    "                utils.save_image(color_images[idx], save_dir, \"gt\" + str(itr // 100))\n",
    "                utils.save_image(pred[idx].astype(np.float64), save_dir, \"pred\" + str(itr // 100))\n",
    "                print(\"%s --> Model saved\" % datetime.datetime.now())\n",
    "\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    "\n",
    "            if itr % 10000 == 0:\n",
    "                FLAGS.learning_rate /= 2\n",
    "elif FLAGS.mode == \"test\":\n",
    "    count = 10\n",
    "    l_image, color_images = batch_reader_testing.get_N_images(count)\n",
    "    feed_dict = {images: l_image, lab_images: color_images, train_phase: False}\n",
    "    save_dir = os.path.join(FLAGS.logs_dir, \"image_pred\")\n",
    "    pred = sess.run(pred_image, feed_dict=feed_dict)\n",
    "    for itr in range(count):\n",
    "        utils.save_image(color_images[itr], save_dir, \"gt\" + str(itr))\n",
    "        utils.save_image(pred[itr].astype(np.float64), save_dir, \"pred\" + str(itr))\n",
    "    print(\"--- Images saved on test run ---\")\n",
    "    \n",
    "plot_train_loss = False\n",
    "if plot_train_loss == True:\n",
    "    plt.semilogy(mse_train_list[0:MAX_ITERATION:step], '-ro', label=\"train loss\") # train loss\n",
    "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "    plt.xlabel('iteration index')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
